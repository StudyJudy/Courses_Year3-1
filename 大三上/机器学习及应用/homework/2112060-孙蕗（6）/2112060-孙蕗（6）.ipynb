{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8d3cb7",
   "metadata": {},
   "source": [
    "## å®éªŒè¦æ±‚\n",
    "### æˆªæ­¢æ—¥æœŸï¼š12æœˆ15æ—¥\n",
    "ä½œä¸šçš„æäº¤æ ¼å¼å‚è€ƒä¹‹å‰çš„è¯´æ˜ï¼Œæäº¤åˆ°18329300691@163.com\n",
    "### åŸºæœ¬è¦æ±‚\n",
    "a)\tåŸºäº Watermelon-train1æ•°æ®é›†ï¼ˆåªæœ‰ç¦»æ•£å±æ€§ï¼‰ï¼Œæ„é€ ID3å†³ç­–æ ‘ï¼›\n",
    "b)\tåŸºäºæ„é€ çš„ ID3 å†³ç­–æ ‘ï¼Œå¯¹æ•°æ®é›† Watermelon-test1è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»ç²¾åº¦ï¼›\n",
    "### ä¸­çº§è¦æ±‚\n",
    "a)  å¯¹æ•°æ®é›†Watermelon-train2ï¼Œæ„é€ C4.5æˆ–è€…CARTå†³ç­–æ ‘ï¼Œè¦æ±‚å¯ä»¥å¤„ç†è¿ç»­å‹å±æ€§ï¼›\n",
    "b)\tå¯¹æµ‹è¯•é›†Watermelon-test2è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»ç²¾åº¦ï¼›\n",
    "### é«˜çº§è¦æ±‚\n",
    "ä½¿ç”¨ä»»æ„çš„å‰ªæç®—æ³•å¯¹æ„é€ çš„å†³ç­–æ ‘ï¼ˆåŸºæœ¬è¦æ±‚å’Œä¸­çº§è¦æ±‚æ„é€ çš„æ ‘ï¼‰è¿›è¡Œå‰ªæï¼Œè§‚å¯Ÿæµ‹è¯•é›†åˆçš„åˆ†ç±»ç²¾åº¦æ˜¯å¦æœ‰æå‡ï¼Œç»™å‡ºåˆ†æè¿‡ç¨‹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8575b",
   "metadata": {},
   "source": [
    "\n",
    "## ä»€ä¹ˆæ˜¯å†³ç­–æ ‘\n",
    "<img src=\"https://s2.loli.net/2022/10/23/yTpSLmgFWOh4Y5d.png\" style=\"zoom:66%\" align=\"left\"/>\n",
    "\n",
    "\n",
    "## å†³ç­–æ ‘çš„åˆ’åˆ†\n",
    "- å†³ç­–æ ‘ä¸»è¦åˆ†ä¸ºä¸‰ç§ï¼š\n",
    "\tID3ï¼ŒC4.5å’ŒCARTï¼Œå®ƒä»¬åˆ†åˆ«å¯¹åº”çš„**ç‰¹å¾é€‰æ‹©å‡†åˆ™**æ˜¯ä¿¡æ¯å¢ç›Šï¼ˆID3ï¼‰ï¼Œä¿¡æ¯å¢ç›Šæ¯”ï¼ˆC4.5ï¼‰å’ŒåŸºå°¼æŒ‡æ•°ï¼ˆCARTï¼‰ã€‚\n",
    "\tå®ƒä»¬å†³å®šå½“å‰é€‰æ‹©å“ªä¸ªç‰¹å¾è¿›è¡Œæ•°æ®åˆ’åˆ†ï¼Œä½¿å¾—æ ·æœ¬åœ¨å½“ä¸‹èƒ½å¤Ÿè¢«æœ€å¤§ç¨‹åº¦çš„åˆ’åˆ†ã€‚\n",
    "- å¯¹äºç¦»æ•£å˜é‡ï¼Œé€‰å®š**å±æ€§**åˆ†ç±»å³å¯ï¼›\n",
    "- å¯¹äºè¿ç»­å˜é‡ï¼Œéœ€è¦é€‰å®š**åˆ’åˆ†ç‚¹**ã€‚\n",
    "- CARTå’ŒC4.5æ”¯æŒæ•°æ®ç‰¹å¾ä¸º**è¿ç»­åˆ†å¸ƒ**æ—¶çš„å¤„ç†ï¼Œèƒ½å¤Ÿå®Œæˆå¯¹è¿ç»­å±æ€§çš„ç¦»æ•£åŒ–å¤„ç†ï¼Œä¸»è¦é€šè¿‡äºŒå…ƒåˆ‡åˆ†çš„æ–¹å¼æ¥å¤„ç†è¿ç»­å‹å˜é‡ï¼Œè¿™ä¸ªåˆ†è£‚ç‚¹çš„é€‰æ‹©åŸåˆ™æ˜¯ä½¿å¾—åˆ’åˆ†åçš„å­æ ‘ä¸­çš„â€œæ··ä¹±ç¨‹åº¦â€é™ä½ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaeddc2",
   "metadata": {},
   "source": [
    "## C4.5ç®—æ³•\n",
    "- C4.5ç®—æ³•ä¸ID3ç®—æ³•ç›¸ä¼¼ï¼Œå…¶å¯¹ID3ç®—æ³•è¿›è¡Œäº†æ”¹è¿›ã€‚\n",
    "- ä¿¡æ¯å¢ç›Šä½œä¸ºåˆ’åˆ†å‡†åˆ™å­˜åœ¨çš„é—®é¢˜ï¼š\n",
    "\n",
    "     ä¿¡æ¯å¢ç›Šåå‘äºé€‰æ‹©å–å€¼è¾ƒå¤šçš„ç‰¹å¾è¿›è¡Œåˆ’åˆ†ã€‚â½å¦‚å­¦å·è¿™ä¸ªç‰¹å¾ï¼Œæ¯ä¸ªå­¦ç”Ÿéƒ½æœ‰ä¸€ä¸ªä¸åŒçš„å­¦å·ï¼Œå¦‚æœæ ¹æ®å­¦å·å¯¹æ ·æœ¬è¿›è¡Œåˆ†ç±»ï¼Œåˆ™æ¯ä¸ªå­¦ç”Ÿéƒ½å±äºä¸åŒçš„ç±»åˆ«ï¼Œè¿™æ ·æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚è€ŒC4.5åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œç”¨**ä¿¡æ¯å¢ç›Šæ¯”**æ¥é€‰æ‹©ç‰¹å¾ï¼Œå¯ä»¥æ ¡æ­£è¿™ä¸ªé—®é¢˜ã€‚\n",
    "     \n",
    "- ç‰¹ç‚¹\n",
    "  - èƒ½å¤Ÿå®Œæˆå¯¹è¿ç»­å±æ€§çš„ç¦»æ•£åŒ–å¤„ç†\n",
    "  - èƒ½å¤Ÿå¯¹ä¸å®Œæ•´æ•°æ®è¿›è¡Œå¤„ç†\n",
    "  - éœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œå¤šæ¬¡çš„é¡ºåºæ‰«æå’Œæ’åº\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0add97e",
   "metadata": {},
   "source": [
    "\n",
    "## CARTç®—æ³•\n",
    "- ID3å’ŒC4.5è™½ç„¶åœ¨å¯¹è®­ç»ƒæ ·æœ¬é›†çš„å­¦ä¹ ä¸­å¯ä»¥å°½å¯èƒ½å¤šçš„æŒ–æ˜ä¿¡æ¯ï¼Œä½†å…¶ç”Ÿæˆçš„å†³ç­–æ ‘åˆ†æ”¯è¾ƒå¤§ï¼Œè§„æ¨¡è¾ƒå¤§ã€‚ä¸ºäº†ç®€åŒ–å†³ç­–æ ‘çš„è§„æ¨¡ï¼Œæé«˜ç”Ÿæˆå†³ç­–æ ‘çš„æ•ˆç‡ï¼Œå°±å‡ºç°äº†æ ¹æ®**åŸºå°¼æŒ‡æ•°**æ¥é€‰æ‹©çš„CARTï¼› \n",
    "- å¯¹äºç»™å®šçš„æ ·æœ¬é›†åˆ ï¼Œå…¶åŸºå°¼æŒ‡æ•°ä¸ºï¼š $$ {Gini}(D)=1-\\sum_{k=1}^{K}\\left(\\frac{\\left|C_{k}\\right|}{|D|}\\right)^{2} $$\n",
    "   å…¶ä¸­$ğ¶_ğ‘˜$æ˜¯ğ·ä¸­å±äºç¬¬ğ‘˜ç±»çš„æ ·æœ¬å­é›†ï¼ŒKæ˜¯ç±»çš„ä¸ªæ•°ã€‚\n",
    "- åŸºå°¼ç³»æ•°çš„æ€§è´¨ä¸ä¿¡æ¯ç†µä¸€æ ·ï¼š\n",
    "   åº¦é‡éšæœºå˜é‡çš„ä¸ç¡®å®šåº¦çš„å¤§å°ï¼›åŸºå°¼æŒ‡æ•°è¶Šâ¼©è¡¨ç¤ºæ•°æ®çš„çº¯åº¦è¶Šé«˜ï¼Œåä¹‹å…¶å€¼è¶Šå¤§ï¼Œæ ·æœ¬é›†åˆçš„ä¸ç¡®å®šæ€§ä¹Ÿå°±è¶Šå¤§ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721d760b",
   "metadata": {},
   "source": [
    "## å†³ç­–æ ‘çš„å‰ªæ\n",
    "- å†³ç­–æ ‘å¾ˆå®¹æ˜“å‡ºç°**è¿‡æ‹Ÿåˆç°è±¡**ã€‚åŸå› åœ¨äºå­¦ä¹ æ—¶å®Œå…¨è€ƒè™‘çš„æ˜¯å¦‚ä½•æâ¾¼å¯¹è®­ç»ƒæ•°æ®çš„æ­£ç¡®åˆ†ç±»ä»â½½æ„å»ºå‡ºè¿‡äºå¤æ‚çš„å†³ç­–æ ‘ã€‚\n",
    "- è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ç§°ä¸º**å‰ªæ**ï¼Œå³å¯¹å·²ç”Ÿæˆçš„æ ‘è¿›è¡Œç®€åŒ–ã€‚å…·ä½“åœ°ï¼Œå°±æ˜¯ä»å·²ç”Ÿæˆçš„æ ‘ä¸Šè£å‰ªæ‰â¼€äº›å­æ ‘æˆ–å¶èŠ‚ç‚¹ï¼Œå¹¶å°†å…¶æ ¹èŠ‚ç‚¹æˆ–çˆ¶èŠ‚ç‚¹ä½œä¸ºæ–°çš„å¶èŠ‚ç‚¹ã€‚ \n",
    "- å†³ç­–æ ‘çš„å‰ªæåŸºæœ¬ç­–ç•¥æœ‰**é¢„å‰ªæ (Pre-Pruning)** å’Œ **åå‰ªæ (Post-Pruning)**\n",
    "   - **é¢„å‰ªæ**ï¼šæ˜¯æ ¹æ®â¼€äº›åŸåˆ™**ææ—©çš„åœæ­¢æ ‘å¢é•¿**ï¼Œå¦‚æ ‘çš„æ·±åº¦è¾¾åˆ°ç”¨æˆ·æ‰€è¦çš„æ·±åº¦ã€èŠ‚ç‚¹ä¸­æ ·æœ¬ä¸ªæ•°å°‘äºç”¨æˆ·æŒ‡å®šä¸ªæ•°ã€ä¸çº¯åº¦æŒ‡æ ‡ä¸‹é™çš„å¹…åº¦å°äºç”¨æˆ·æŒ‡å®šçš„å¹…åº¦ç­‰ã€‚ \n",
    "   - **åå‰ªæ**ï¼šæ˜¯é€šè¿‡åœ¨å®Œå…¨ç”Ÿé•¿çš„æ ‘ä¸Šå‰ªå»åˆ†æå®ç°çš„ï¼Œé€šè¿‡åˆ é™¤èŠ‚ç‚¹çš„åˆ†æ”¯æ¥å‰ªå»æ ‘èŠ‚ç‚¹ã€‚æ˜¯åœ¨ç”Ÿæˆå†³ç­–æ ‘ä¹‹å**è‡ªåº•å‘ä¸Š**çš„å¯¹æ ‘ä¸­æ‰€æœ‰çš„éå¶ç»“ç‚¹è¿›â¾é€ä¸€è€ƒå¯Ÿ ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17985d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff77560c",
   "metadata": {},
   "source": [
    "### åŸºæœ¬è¦æ±‚\n",
    "a)\tåŸºäº Watermelon-train1æ•°æ®é›†ï¼ˆåªæœ‰ç¦»æ•£å±æ€§ï¼‰ï¼Œæ„é€ ID3å†³ç­–æ ‘ï¼›\n",
    "\n",
    "b)\tåŸºäºæ„é€ çš„ ID3 å†³ç­–æ ‘ï¼Œå¯¹æ•°æ®é›† Watermelon-test1è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»ç²¾åº¦ï¼›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "89d310ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c86d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ•°æ®\n",
    "watermelon_train1_data = pd.read_csv(r\"C:/Users/LENOVO/Desktop/ML-6/Watermelon-train1.csv\", encoding='gbk')  \n",
    "watermelon_test1_data = pd.read_csv(r\"C:/Users/LENOVO/Desktop/ML-6/Watermelon-test1.csv\", encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b4ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†åˆ†ç±»æ ‡ç­¾è½¬æ¢ä¸ºæ•°å€¼è¡¨ç¤ºï¼Œæ˜¯->1ï¼Œå¦->0\n",
    "watermelon_train1_data['å¥½ç“œ'] = watermelon_train1_data['å¥½ç“œ'].map({'æ˜¯': 1, 'å¦': 0})\n",
    "watermelon_test1_data['å¥½ç“œ'] = watermelon_test1_data['å¥½ç“œ'].map({'æ˜¯': 1, 'å¦': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac0acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹ç¦»æ•£ç‰¹å¾è¿›è¡Œç‹¬çƒ­ç¼–ç \n",
    "watermelon_train1_data = pd.get_dummies(watermelon_train1_data, columns=['è‰²æ³½', 'æ ¹è’‚', 'æ•²å£°', 'çº¹ç†'])\n",
    "watermelon_test1_data = pd.get_dummies(watermelon_test1_data, columns=['è‰²æ³½', 'æ ¹è’‚', 'æ•²å£°', 'çº¹ç†'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b0f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æå–ç‰¹å¾å’Œæ ‡ç­¾\n",
    "X_train = watermelon_train1_data.drop('å¥½ç“œ', axis=1)\n",
    "y_train = watermelon_train1_data['å¥½ç“œ']\n",
    "\n",
    "X_test = watermelon_test1_data.drop('å¥½ç“œ', axis=1)\n",
    "y_test = watermelon_test1_data['å¥½ç“œ']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ec82be",
   "metadata": {},
   "source": [
    "\n",
    "## ID3ç®—æ³•\n",
    "- ID3ç®—æ³•çš„æ ¸â¼¼æ€æƒ³åº”ç”¨ä¿¡æ¯å¢ç›Šå‡†åˆ™ä½œä¸ºæ ‡å‡†,ä»‹ç»ä¿¡æ¯å¢ç›Šä¹‹å‰é¦–å…ˆä»‹ç»ä¸€ä¸‹ä¿¡æ¯ç†µå’Œæ¡ä»¶ç†µï¼š \n",
    "- ç†µï¼ˆentropyï¼‰æ¦‚å¿µï¼š\n",
    "\t    1948å¹´ï¼Œé¦™å†œæå‡ºäº†â€œä¿¡æ¯ç†µâ€çš„æ¦‚å¿µã€‚åœ¨ä¿¡æ¯è®ºä¸æ¦‚ç‡ç»Ÿè®¡ä¸­ï¼Œç†µæ˜¯è¡¨ç¤ºéšæœºå˜é‡ä¸ç¡®å®šæ€§çš„é‡ã€‚Xæ˜¯â¼€ä¸ªå–å€¼ä¸ºæœ‰é™ä¸ªçš„ç¦»æ•£éšæœºå˜é‡ï¼Œ\n",
    "$$ H(X)=-\\sum_{i=1}^{n} p\\left(x_{i}\\right) \\log p\\left(x_{i}\\right)$$ \n",
    "$ğ»(ğ‘‹)$å°±è¢«ç§°ä½œéšæœºå˜é‡ğ‘‹çš„ç†µï¼Œå®ƒè¡¨ç¤ºéšæœºå˜é‡ä¸ç¡®å®šçš„åº¦é‡ã€‚ç†µå–å€¼è¶Šå¤§ï¼Œéšæœºå˜é‡ä¸ç¡®å®šæ€§è¶Šå¤§ã€‚å½“éšæœºå˜é‡ä¸ºå‡åŒ€åˆ†å¸ƒæ—¶ï¼Œç†µæœ€å¤§ã€‚å½“æŸä¸€çŠ¶æ€æ¦‚ç‡å–å€¼ä¸º1æ—¶ï¼Œç†µçš„å€¼ä¸ºé›¶ã€‚\n",
    "\n",
    "### ID3ç®—æ³•-æ¡ä»¶ç†µå’Œä¿¡æ¯å¢ç›Š\n",
    "- æ¡ä»¶ç†µ $ğ»(ğ‘Œâˆ£ğ‘‹)$ ï¼š\n",
    "\tè¡¨ç¤ºåœ¨å·²çŸ¥éšæœºå˜é‡ğ‘‹çš„æ¡ä»¶ä¸‹éšæœºå˜é‡ğ‘Œçš„ä¸ç¡®å®šæ€§ï¼Œå®šä¹‰ä¸ºç»™å®šğ‘‹æ¡ä»¶ä¸‹ğ‘Œçš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒçš„ç†µå¯¹ğ‘‹çš„æ•°å­¦æœŸæœ›:\n",
    "$$H(Y \\mid X)=\\sum_{x} p(x) H(Y \\mid X=x) =-\\sum_{x} p(x) \\sum_{y} p(y \\mid x) \\log p(y \\mid x)$$\n",
    "\n",
    "- ç‰¹å¾ğ´å¯¹æ•°æ®é›†ğ·çš„ä¿¡æ¯å¢ç›Šå°±æ˜¯ç†µ$ğ»(ğ·)$ä¸æ¡ä»¶ç†µ$ğ»(ğ·|ğ´)$ä¹‹å·®:\n",
    "$$ğ»(ğ·)âˆ’ğ»(ğ·âˆ£ğ´)$$\n",
    "\n",
    "\tè¡¨ç¤ºå·²çŸ¥ç‰¹å¾ğ´çš„ä¿¡æ¯è€Œä½¿å¾—æ•°æ®é›†ğ·çš„ä¿¡æ¯ä¸ç¡®å®šå‡å°‘çš„ç¨‹åº¦ã€‚ä¿¡æ¯å¢ç›Šè¶Šå¤§çš„ç‰¹å¾ä»£è¡¨å…¶å…·æœ‰æ›´å¼ºçš„åˆ†ç±»èƒ½åŠ›ï¼Œæ‰€ä»¥æˆ‘ä»¬å°±è¦**é€‰æ‹©èƒ½å¤Ÿä½¿æ•°æ®çš„ä¸ç¡®å®šç¨‹åº¦å‡å°‘æœ€å¤šçš„ç‰¹å¾**ï¼Œä¹Ÿå°±æ˜¯ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ã€‚\n",
    "\n",
    "### ID3ç®—æ³•-åœæ­¢æ¡ä»¶\n",
    "- å†³ç­–æ ‘çš„ç”Ÿæˆ:\n",
    "\n",
    "\tä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œè®¡ç®—æ‰€æœ‰å¯èƒ½ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šï¼Œé€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ä½œä¸ºåˆ’åˆ†è¯¥èŠ‚ç‚¹çš„ç‰¹å¾ï¼Œæ ¹æ®è¯¥ç‰¹å¾çš„ä¸åŒå–å€¼å»ºç«‹å­èŠ‚ç‚¹ï¼›\n",
    "\tåœ¨å¯¹å­èŠ‚ç‚¹é€’å½’åœ°è°ƒç”¨ä»¥ä¸Šæ–¹æ³•ï¼Œç›´åˆ°è¾¾åˆ°åœæ­¢æ¡ä»¶ï¼Œå¾—åˆ°â¼€ä¸ªå†³ç­–æ ‘ã€‚\n",
    "    \n",
    "    \n",
    "- è¿­ä»£åœæ­¢æ¡ä»¶ï¼š\n",
    "  1. å½“å‰ç»“ç‚¹æ‰€æœ‰æ ·æœ¬éƒ½å±äºåŒâ¼€ç±»åˆ«ï¼›\n",
    "  2. å½“å‰ç»“ç‚¹çš„æ‰€æœ‰å±æ€§å€¼éƒ½ç›¸åŒï¼Œæ²¡æœ‰å‰©ä½™å±æ€§å¯ç”¨æ¥è¿›ä¸€æ­¥åˆ’åˆ†æ ·æœ¬ï¼›\n",
    "  3. è¾¾åˆ°æœ€å¤§æ ‘æ·±ï¼›\n",
    "  4. è¾¾åˆ°å¶å­ç»“ç‚¹çš„æœ€å°æ ·æœ¬æ•°ï¼›\n",
    "\n",
    "### ID3ç®—æ³•ä¸¾ä¾‹\n",
    "\n",
    "<img src=\"https://s2.loli.net/2022/10/23/p7gSQeYGnoBCd2i.png\" style=\"zoom:64%\" />\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\operatorname{Info}^{\\text {In }}(D)=-\\frac{9}{14} \\log _{2}\\left(\\frac{9}{14}\\right)-\\frac{5}{14} \\log _{2}\\left(\\frac{5}{14}\\right)=0.940 \\\\\n",
    "\\operatorname{Infoage~}(D)=\\frac{5}{14} \\times\\left(-\\frac{2}{5} \\times \\log _{2} \\frac{2}{5}-\\frac{3}{5} \\times \\log _{2} \\frac{3}{5}\\right)+\\frac{4}{14} \\times\\left(-\\frac{4}{4} \\times \\log _{2} \\frac{4}{4}-\\frac{0}{4} \\times \\log _{2} \\frac{0}{4}\\right) \n",
    "+\\frac{5}{14} \\times\\left(-\\frac{2}{5} \\times \\log _{2} \\frac{2}{5}-\\frac{3}{5} \\times \\log _{2} \\frac{3}{5}\\right)=0.694 \\\\\n",
    "\\text { Gain }(\\text { age })=\\operatorname{Info}(D)-\\operatorname{InfO}_{\\text {age }}(D) =0.940-0.694=0.246\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<img src=\"https://s2.loli.net/2022/10/23/1zAnHWKRgQ9FaJV.png\" style=\"zoom:72%\" />\n",
    "ç±»ä¼¼åœ°ï¼Œ\n",
    "Gain(income)=0.029    \n",
    "Gain(student)=0.151    \n",
    "Gain(credit_rating)=0.048\n",
    "\n",
    "æ‰€ä»¥ï¼Œé€‰æ‹©ageä½œä¸ºç¬¬ä¸€ä¸ªæ ¹èŠ‚ç‚¹\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160ac51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ„å»º ID3 å†³ç­–æ ‘æ¨¡å‹\n",
    "dt_classifier = DecisionTreeClassifier(criterion='entropy')\n",
    "dt_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13874a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ†ç±»ç²¾åº¦ï¼š0.70\n"
     ]
    }
   ],
   "source": [
    "# å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# è¾“å‡ºåˆ†ç±»ç²¾åº¦\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"åˆ†ç±»ç²¾åº¦ï¼š{accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6875744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, value=None, result=None):\n",
    "        self.feature = feature  # ç‰¹å¾åˆ—å\n",
    "        self.value = value  # ç‰¹å¾å–å€¼\n",
    "        self.result = result  # ç»“æœæ ‡ç­¾\n",
    "        self.children = {}  # å­èŠ‚ç‚¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a88d86",
   "metadata": {},
   "source": [
    "Xæ˜¯â¼€ä¸ªå–å€¼ä¸ºæœ‰é™ä¸ªçš„ç¦»æ•£éšæœºå˜é‡ï¼Œ\n",
    "$$ H(X)=-\\sum_{i=1}^{n} p\\left(x_{i}\\right) \\log p\\left(x_{i}\\right)$$ \n",
    "$ğ»(ğ‘‹)$å°±è¢«ç§°ä½œéšæœºå˜é‡ğ‘‹çš„ç†µï¼Œå®ƒè¡¨ç¤ºéšæœºå˜é‡ä¸ç¡®å®šçš„åº¦é‡ã€‚ç†µå–å€¼è¶Šå¤§ï¼Œéšæœºå˜é‡ä¸ç¡®å®šæ€§è¶Šå¤§ã€‚å½“éšæœºå˜é‡ä¸ºå‡åŒ€åˆ†å¸ƒæ—¶ï¼Œç†µæœ€å¤§ã€‚å½“æŸä¸€çŠ¶æ€æ¦‚ç‡å–å€¼ä¸º1æ—¶ï¼Œç†µçš„å€¼ä¸ºé›¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b0e5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—ç†µ\n",
    "def entropy(y):\n",
    "    unique_labels, counts = np.unique(y, return_counts=True)# è·å–ç±»åˆ«æ ‡ç­¾åŠå…¶å¯¹åº”çš„å‡ºç°æ¬¡æ•°\n",
    "    probabilities = counts / len(y)# è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡\n",
    "    return -np.sum(probabilities * np.log2(probabilities + 1e-10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f4014",
   "metadata": {},
   "source": [
    "- æ¡ä»¶ç†µ $ğ»(ğ‘Œâˆ£ğ‘‹)$ ï¼š\n",
    "\tè¡¨ç¤ºåœ¨å·²çŸ¥éšæœºå˜é‡ğ‘‹çš„æ¡ä»¶ä¸‹éšæœºå˜é‡ğ‘Œçš„ä¸ç¡®å®šæ€§ï¼Œå®šä¹‰ä¸ºç»™å®šğ‘‹æ¡ä»¶ä¸‹ğ‘Œçš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒçš„ç†µå¯¹ğ‘‹çš„æ•°å­¦æœŸæœ›:\n",
    "$$H(Y \\mid X)=\\sum_{x} p(x) H(Y \\mid X=x) =-\\sum_{x} p(x) \\sum_{y} p(y \\mid x) \\log p(y \\mid x)$$\n",
    "\n",
    "- ç‰¹å¾ğ´å¯¹æ•°æ®é›†ğ·çš„ä¿¡æ¯å¢ç›Šå°±æ˜¯ç†µ$ğ»(ğ·)$ä¸æ¡ä»¶ç†µ$ğ»(ğ·|ğ´)$ä¹‹å·®:\n",
    "$$ğ»(ğ·)âˆ’ğ»(ğ·âˆ£ğ´)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c177c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—ä¿¡æ¯å¢ç›Š\n",
    "def information_gain(X, y, feature):\n",
    "    # è®¡ç®—åŸºç¡€ç†µï¼ˆå³æœªè¿›è¡Œä»»ä½•ç‰¹å¾åˆ’åˆ†æ—¶çš„ç†µï¼‰\n",
    "    base_entropy = entropy(y)\n",
    "    # è·å–ç‰¹å¾åˆ—çš„å”¯ä¸€å€¼\n",
    "    unique_values = X[feature].unique()\n",
    "    # åˆå§‹åŒ–åŠ æƒç†µ\n",
    "    weighted_entropy = 0\n",
    "    # éå†ç‰¹å¾çš„æ¯ä¸ªå–å€¼\n",
    "    for value in unique_values:\n",
    "         # è·å–ç‰¹å¾Xå–å€¼ä¸ºvalueçš„æ ·æœ¬çš„ç´¢å¼•\n",
    "        subset_indices = X[X[feature] == value].index\n",
    "          # è®¡ç®—åœ¨ç‰¹å¾ X å–å€¼ä¸º value çš„æ¡ä»¶ä¸‹ç›®æ ‡å˜é‡ y çš„ç†µ\n",
    "        subset_entropy = entropy(y.loc[subset_indices])\n",
    "         # å°†æ¡ä»¶ç†µåŠ æƒç´¯åŠ \n",
    "        weighted_entropy += len(subset_indices) / len(y) * subset_entropy\n",
    " # è®¡ç®—ä¿¡æ¯å¢ç›Š\n",
    "    return base_entropy - weighted_entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aafbdf",
   "metadata": {},
   "source": [
    "- å†³ç­–æ ‘çš„ç”Ÿæˆ:\n",
    "\n",
    "\tä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œè®¡ç®—æ‰€æœ‰å¯èƒ½ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šï¼Œé€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ä½œä¸ºåˆ’åˆ†è¯¥èŠ‚ç‚¹çš„ç‰¹å¾ï¼Œæ ¹æ®è¯¥ç‰¹å¾çš„ä¸åŒå–å€¼å»ºç«‹å­èŠ‚ç‚¹ï¼›\n",
    "\tåœ¨å¯¹å­èŠ‚ç‚¹é€’å½’åœ°è°ƒç”¨ä»¥ä¸Šæ–¹æ³•ï¼Œç›´åˆ°è¾¾åˆ°åœæ­¢æ¡ä»¶ï¼Œå¾—åˆ°â¼€ä¸ªå†³ç­–æ ‘ã€‚\n",
    "    \n",
    "    \n",
    "- è¿­ä»£åœæ­¢æ¡ä»¶ï¼š\n",
    "  1. å½“å‰ç»“ç‚¹æ‰€æœ‰æ ·æœ¬éƒ½å±äºåŒâ¼€ç±»åˆ«ï¼›\n",
    "  2. å½“å‰ç»“ç‚¹çš„æ‰€æœ‰å±æ€§å€¼éƒ½ç›¸åŒï¼Œæ²¡æœ‰å‰©ä½™å±æ€§å¯ç”¨æ¥è¿›ä¸€æ­¥åˆ’åˆ†æ ·æœ¬ï¼›\n",
    "  3. è¾¾åˆ°æœ€å¤§æ ‘æ·±ï¼›\n",
    "  4. è¾¾åˆ°å¶å­ç»“ç‚¹çš„æœ€å°æ ·æœ¬æ•°ï¼›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86887023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºID3å†³ç­–æ ‘\n",
    "def id3(X, y, features):   \n",
    "    # å¦‚æœç›®æ ‡å˜é‡yçš„å–å€¼åªæœ‰ä¸€ä¸ªï¼Œè¿”å›ä¸€ä¸ªå¶å­èŠ‚ç‚¹ï¼Œè¡¨ç¤ºè¯¥å­æ ‘çš„é¢„æµ‹ç»“æœä¸ºè¯¥å”¯ä¸€å–å€¼\n",
    "    if len(set(y)) == 1:\n",
    "        return Node(result=y.iloc[0])\n",
    "\n",
    "    # å¦‚æœç‰¹å¾é›†ä¸ºç©ºï¼Œè¡¨ç¤ºæ‰€æœ‰ç‰¹å¾éƒ½å·²ç»ä½¿ç”¨è¿‡ã€‚æ²¡æœ‰å‰©ä½™å±æ€§å¯ç”¨æ¥è¿›ä¸€æ­¥åˆ’åˆ†æ ·æœ¬ï¼Œåœæ­¢è¿­ä»£\n",
    "    # è¿”å›ä¸€ä¸ªå¶å­èŠ‚ç‚¹ï¼Œè¡¨ç¤ºè¯¥å­æ ‘çš„é¢„æµ‹ç»“æœä¸ºç›®æ ‡å˜é‡yä¸­å‡ºç°æ¬¡æ•°æœ€å¤šçš„å–å€¼\n",
    "    if len(features) == 0:\n",
    "        return Node(result=y.mode().iloc[0])\n",
    "\n",
    "    # é€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ä½œä¸ºå½“å‰èŠ‚ç‚¹çš„åˆ’åˆ†ç‰¹å¾\n",
    "    best_feature = max(features, key=lambda feature: information_gain(X, y, feature))\n",
    "    root = Node(feature=best_feature)\n",
    "\n",
    "     # å¯¹äºåˆ’åˆ†ç‰¹å¾çš„æ¯ä¸ªå–å€¼ï¼Œé€’å½’æ„å»ºå­æ ‘\n",
    "    for value in X[best_feature].unique():\n",
    "        # æ‰¾åˆ°åˆ’åˆ†ç‰¹å¾å–å€¼ä¸ºvalueçš„æ ·æœ¬ç´¢å¼•\n",
    "        subset_indices = X[X[best_feature] == value].index\n",
    "        # é€’å½’æ„å»ºå­æ ‘\n",
    "        child_node = id3(X.loc[subset_indices], y.loc[subset_indices], features - {best_feature})\n",
    "         # å°†å­æ ‘åŠ å…¥å½“å‰èŠ‚ç‚¹çš„å­èŠ‚ç‚¹å­—å…¸\n",
    "        root.children[value] = child_node\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52df40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¢„æµ‹å•ä¸ªæ ·æœ¬\n",
    "def predict(node, sample):   \n",
    "    if node.result is not None:\n",
    "        return node.result\n",
    "\n",
    "    value = sample[node.feature]\n",
    "    if value in node.children:\n",
    "        return predict(node.children[value], sample)\n",
    "    else:\n",
    "        # å¦‚æœæµ‹è¯•é›†ä¸­å‡ºç°äº†è®­ç»ƒé›†ä¸­æœªè§è¿‡çš„å–å€¼ï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤å€¼\n",
    "        return node.children[list(node.children.keys())[0]].result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c59f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¹é‡é¢„æµ‹\n",
    "def batch_predict(node, X):    \n",
    "    return X.apply(lambda sample: predict(node, sample), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb3b2a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æå–ç‰¹å¾å’Œæ ‡ç­¾\n",
    "X_train = watermelon_train1_data.drop('å¥½ç“œ', axis=1)\n",
    "y_train = watermelon_train1_data['å¥½ç“œ']\n",
    "\n",
    "X_test = watermelon_test1_data.drop('å¥½ç“œ', axis=1)\n",
    "y_test = watermelon_test1_data['å¥½ç“œ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b611ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·å–ç‰¹å¾é›†åˆ\n",
    "features = set(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bd9b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºID3å†³ç­–æ ‘\n",
    "root = id3(X_train, y_train, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6bbc629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ†ç±»ç²¾åº¦ï¼š 0.70\n"
     ]
    }
   ],
   "source": [
    "# å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹\n",
    "y_pred = batch_predict(root, X_test)\n",
    "\n",
    "# è¾“å‡ºåˆ†ç±»ç²¾åº¦\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"åˆ†ç±»ç²¾åº¦ï¼š{accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd11877b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d14b3d2b",
   "metadata": {},
   "source": [
    "### ä¸­çº§è¦æ±‚\n",
    "a)  å¯¹æ•°æ®é›†Watermelon-train2ï¼Œæ„é€ C4.5æˆ–è€…CARTå†³ç­–æ ‘ï¼Œè¦æ±‚å¯ä»¥å¤„ç†è¿ç»­å‹å±æ€§ï¼›\n",
    "\n",
    "b)\tå¯¹æµ‹è¯•é›†Watermelon-test2è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»ç²¾åº¦ï¼›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d4c777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ•°æ®\n",
    "watermelon_train2_data = pd.read_csv(r\"C:/Users/LENOVO/Desktop/ML-6/Watermelon-train2.csv\", encoding='gbk')  \n",
    "watermelon_test2_data = pd.read_csv(r\"C:/Users/LENOVO/Desktop/ML-6/Watermelon-test2.csv\", encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9756eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†åˆ†ç±»æ ‡ç­¾è½¬æ¢ä¸ºæ•°å€¼è¡¨ç¤ºï¼Œæ˜¯->1ï¼Œå¦->0\n",
    "watermelon_train2_data['å¥½ç“œ'] = watermelon_train2_data['å¥½ç“œ'].map({'æ˜¯': 1, 'å¦': 0})\n",
    "watermelon_test2_data['å¥½ç“œ'] = watermelon_test2_data['å¥½ç“œ'].map({'æ˜¯': 1, 'å¦': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6638cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†ç±»åˆ«å‹ç‰¹å¾è½¬æ¢ä¸ºæ•°å­—\n",
    "le = LabelEncoder()\n",
    "for column in watermelon_train2_data.columns:\n",
    "    if watermelon_train2_data[column].dtype == 'object':\n",
    "        watermelon_train2_data[column] = le.fit_transform(watermelon_train2_data[column])\n",
    "        \n",
    "for column in watermelon_test2_data.columns:\n",
    "    if watermelon_test2_data[column].dtype == 'object':\n",
    "        watermelon_test2_data[column] = le.fit_transform(watermelon_test2_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c48e2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿›è¡Œç‹¬çƒ­ç¼–ç \n",
    "# watermelon_train2_data = pd.get_dummies(watermelon_train2_data, columns=['è‰²æ³½', 'æ ¹è’‚', 'æ•²å£°', 'çº¹ç†', 'å¯†åº¦'])\n",
    "# watermelon_test2_data = pd.get_dummies(watermelon_test2_data, columns=['è‰²æ³½', 'æ ¹è’‚', 'æ•²å£°', 'çº¹ç†','å¯†åº¦'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8540ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†å‰²è®­ç»ƒé›†ç‰¹å¾å’Œæ ‡ç­¾\n",
    "X_train = watermelon_train2_data.drop(columns=['å¥½ç“œ'])\n",
    "y_train = watermelon_train2_data ['å¥½ç“œ']\n",
    "\n",
    "# åˆ†å‰²æµ‹è¯•é›†ç‰¹å¾å’Œæ ‡ç­¾\n",
    "X_test = watermelon_test2_data.drop(columns=['å¥½ç“œ'])\n",
    "y_test = watermelon_test2_data['å¥½ç“œ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd7383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1bd22c3",
   "metadata": {},
   "source": [
    "### å†³ç­–æ ‘çš„åˆ’åˆ†\n",
    "- å†³ç­–æ ‘ä¸»è¦åˆ†ä¸ºä¸‰ç§ï¼š\n",
    "\tID3ï¼ŒC4.5å’ŒCARTï¼Œå®ƒä»¬åˆ†åˆ«å¯¹åº”çš„**ç‰¹å¾é€‰æ‹©å‡†åˆ™**æ˜¯ä¿¡æ¯å¢ç›Šï¼ˆID3ï¼‰ï¼Œä¿¡æ¯å¢ç›Šæ¯”ï¼ˆC4.5ï¼‰å’ŒåŸºå°¼æŒ‡æ•°ï¼ˆCARTï¼‰ã€‚\n",
    "\tå®ƒä»¬å†³å®šå½“å‰é€‰æ‹©å“ªä¸ªç‰¹å¾è¿›è¡Œæ•°æ®åˆ’åˆ†ï¼Œä½¿å¾—æ ·æœ¬åœ¨å½“ä¸‹èƒ½å¤Ÿè¢«æœ€å¤§ç¨‹åº¦çš„åˆ’åˆ†ã€‚\n",
    "- å¯¹äºç¦»æ•£å˜é‡ï¼Œé€‰å®š**å±æ€§**åˆ†ç±»å³å¯ï¼›\n",
    "- å¯¹äºè¿ç»­å˜é‡ï¼Œéœ€è¦é€‰å®š**åˆ’åˆ†ç‚¹**ã€‚\n",
    "- CARTå’ŒC4.5æ”¯æŒæ•°æ®ç‰¹å¾ä¸º**è¿ç»­åˆ†å¸ƒ**æ—¶çš„å¤„ç†ï¼Œèƒ½å¤Ÿå®Œæˆå¯¹è¿ç»­å±æ€§çš„ç¦»æ•£åŒ–å¤„ç†ï¼Œä¸»è¦é€šè¿‡äºŒå…ƒåˆ‡åˆ†çš„æ–¹å¼æ¥å¤„ç†è¿ç»­å‹å˜é‡ï¼Œè¿™ä¸ªåˆ†è£‚ç‚¹çš„é€‰æ‹©åŸåˆ™æ˜¯ä½¿å¾—åˆ’åˆ†åçš„å­æ ‘ä¸­çš„â€œæ··ä¹±ç¨‹åº¦â€é™ä½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dccfdc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ„å»ºC4.5å†³ç­–æ ‘\n",
    "c4_5_classifier = DecisionTreeClassifier(criterion='entropy')\n",
    "c4_5_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78ea324b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 Classification Accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "# é¢„æµ‹å¹¶è¾“å‡ºåˆ†ç±»ç²¾åº¦\n",
    "y_pred_c4_5 = c4_5_classifier.predict(X_test)\n",
    "accuracy_c4_5 = accuracy_score(y_test, y_pred_c4_5)\n",
    "print(f\"C4.5 Classification Accuracy: {accuracy_c4_5:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc210241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement c45 (from versions: none)\n",
      "ERROR: No matching distribution found for c45\n"
     ]
    }
   ],
   "source": [
    "pip install c45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7854d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ„å»ºCARTå†³ç­–æ ‘\n",
    "cart_classifier = DecisionTreeClassifier(criterion='gini')\n",
    "cart_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4534042c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Classification Accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "# é¢„æµ‹å¹¶è¾“å‡ºåˆ†ç±»ç²¾åº¦\n",
    "y_pred_cart = cart_classifier.predict(X_test)\n",
    "accuracy_cart = accuracy_score(y_test, y_pred_cart)\n",
    "print(f\"CART Classification Accuracy: {accuracy_cart:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b9a0c",
   "metadata": {},
   "source": [
    "### C4.5ç®—æ³•\n",
    "- C4.5ç®—æ³•ä¸ID3ç®—æ³•ç›¸ä¼¼ï¼Œå…¶å¯¹ID3ç®—æ³•è¿›è¡Œäº†æ”¹è¿›ã€‚\n",
    "- ä¿¡æ¯å¢ç›Šä½œä¸ºåˆ’åˆ†å‡†åˆ™å­˜åœ¨çš„é—®é¢˜ï¼š\n",
    "\n",
    "     ä¿¡æ¯å¢ç›Šåå‘äºé€‰æ‹©å–å€¼è¾ƒå¤šçš„ç‰¹å¾è¿›è¡Œåˆ’åˆ†ã€‚â½å¦‚å­¦å·è¿™ä¸ªç‰¹å¾ï¼Œæ¯ä¸ªå­¦ç”Ÿéƒ½æœ‰ä¸€ä¸ªä¸åŒçš„å­¦å·ï¼Œå¦‚æœæ ¹æ®å­¦å·å¯¹æ ·æœ¬è¿›è¡Œåˆ†ç±»ï¼Œåˆ™æ¯ä¸ªå­¦ç”Ÿéƒ½å±äºä¸åŒçš„ç±»åˆ«ï¼Œè¿™æ ·æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚è€ŒC4.5åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œç”¨**ä¿¡æ¯å¢ç›Šæ¯”**æ¥é€‰æ‹©ç‰¹å¾ï¼Œå¯ä»¥æ ¡æ­£è¿™ä¸ªé—®é¢˜ã€‚\n",
    "     \n",
    "- ç‰¹ç‚¹\n",
    "  - èƒ½å¤Ÿå®Œæˆå¯¹è¿ç»­å±æ€§çš„ç¦»æ•£åŒ–å¤„ç†\n",
    "  - èƒ½å¤Ÿå¯¹ä¸å®Œæ•´æ•°æ®è¿›è¡Œå¤„ç†\n",
    "  - éœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œå¤šæ¬¡çš„é¡ºåºæ‰«æå’Œæ’åº\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0adb498",
   "metadata": {},
   "outputs": [],
   "source": [
    "class C45DecisionTree:\n",
    "    \n",
    "    \"\"\"\n",
    "    min_samples_split: int, optional (default=2)\n",
    "          èŠ‚ç‚¹åˆ†è£‚çš„æœ€å°æ ·æœ¬æ•°\n",
    "    max_depth: int or None, optional (default=None)\n",
    "          æ ‘çš„æœ€å¤§æ·±åº¦ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™èŠ‚ç‚¹ä¼šä¸€ç›´åˆ†è£‚ï¼Œç›´åˆ°æ¯ä¸ªå¶å­èŠ‚ç‚¹çš„æ ·æœ¬æ•°å°äºmin_samples_split     \n",
    "    tree: dict\n",
    "          å­˜å‚¨æ„å»ºå¥½çš„å†³ç­–æ ‘çš„å­—å…¸    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, min_samples_split=2, max_depth=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    # è®¡ç®—ä¿¡æ¯ç†µ\n",
    "    def _calculate_entropy(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "    \n",
    "    # æ ¹æ®è®­ç»ƒæ•°æ®æ‹ŸåˆC4.5å†³ç­–æ ‘\n",
    "    def fit(self, X, y):\n",
    "        features = X.columns\n",
    "        data = pd.concat([X, y], axis=1)\n",
    "        self.tree = self._build_tree(data, features)\n",
    "\n",
    "    # é€’å½’æ„å»ºC4.5å†³ç­–æ ‘\n",
    "    def _build_tree(self, data, features, depth=0):\n",
    "        # è‹¥æ ·æœ¬æ•°é‡å°äºç­‰äºé˜ˆå€¼æˆ–æ·±åº¦è¾¾åˆ°æœ€å¤§æ·±åº¦ï¼Œåˆ™è¿”å›å¶å­èŠ‚ç‚¹\n",
    "        if len(data) <= self.min_samples_split or (self.max_depth is not None and depth == self.max_depth):\n",
    "            return self._create_leaf_node(data)\n",
    "\n",
    "        # é€‰æ‹©æœ€ä½³ç‰¹å¾å’Œé˜ˆå€¼è¿›è¡Œåˆ†è£‚\n",
    "        selected_feature, threshold = self._choose_best_feature(data, features)\n",
    "\n",
    "        # æ ¹æ®é€‰æ‹©çš„ç‰¹å¾å’Œé˜ˆå€¼è¿›è¡Œåˆ†è£‚\n",
    "        left_data = data[data[selected_feature] <= threshold]\n",
    "        right_data = data[data[selected_feature] > threshold]\n",
    "\n",
    "        # é€’å½’æ„å»ºå·¦å³å­æ ‘\n",
    "        left_subtree = self._build_tree(left_data, features, depth + 1)\n",
    "        right_subtree = self._build_tree(right_data, features, depth + 1)\n",
    "\n",
    "        return {'feature': selected_feature, 'threshold': threshold,\n",
    "                'left': left_subtree, 'right': right_subtree}\n",
    "   \n",
    "    # åˆ›å»ºå¶å­èŠ‚ç‚¹ï¼ŒåŒ…å«æ•°æ®é›†ä¸­å‡ºç°æœ€é¢‘ç¹çš„ç±»åˆ«\n",
    "    def _create_leaf_node(self, data):\n",
    "        values, counts = np.unique(data.iloc[:, -1], return_counts=True)\n",
    "        return {'class': values[np.argmax(counts)]}\n",
    "    \n",
    "    # é€‰æ‹©æœ€ä½³ç‰¹å¾å’Œé˜ˆå€¼è¿›è¡Œåˆ†è£‚\n",
    "    def _choose_best_feature(self, data, features):\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_info_gain_ratio = -1\n",
    "\n",
    "        for feature in features:\n",
    "            if data[feature].dtype == 'object':\n",
    "                # å¤„ç†ç¦»æ•£ç‰¹å¾\n",
    "                info_gain_ratio, threshold = self._calculate_info_gain_ratio(data, feature)\n",
    "            else:\n",
    "                # å¤„ç†è¿ç»­ç‰¹å¾\n",
    "                info_gain_ratio, threshold = self._calculate_info_gain_ratio_continuous(data, feature)\n",
    "\n",
    "            # é€‰æ‹©ä¿¡æ¯å¢ç›Šæ¯”æœ€å¤§çš„ç‰¹å¾å’Œç›¸åº”çš„é˜ˆå€¼\n",
    "            if info_gain_ratio > best_info_gain_ratio:\n",
    "                best_info_gain_ratio = info_gain_ratio\n",
    "                best_feature = feature\n",
    "                best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    # è®¡ç®—ä¿¡æ¯å¢ç›Šæ¯”\n",
    "    def _calculate_info_gain_ratio(self, data, feature):\n",
    "\n",
    "        # è®¡ç®—åŸå§‹æ•°æ®çš„ä¿¡æ¯ç†µ\n",
    "        original_entropy = self._calculate_entropy(data.iloc[:, -1])\n",
    "\n",
    "        # è®¡ç®—æŒ‰å½“å‰ç‰¹å¾åˆ†è£‚åçš„æ¡ä»¶ç†µ\n",
    "        values, counts = np.unique(data[feature], return_counts=True)\n",
    "        weighted_entropy = 0\n",
    "        for value, count in zip(values, counts):\n",
    "            subset_indices = data[data[feature] == value].index\n",
    "            subset_entropy = self._calculate_entropy(data.loc[subset_indices].iloc[:, -1])\n",
    "            weighted_entropy += count / len(data) * subset_entropy\n",
    "\n",
    "        # è®¡ç®—ä¿¡æ¯å¢ç›Š\n",
    "        information_gain = original_entropy - weighted_entropy\n",
    "\n",
    "        # è®¡ç®—åˆ†è£‚ä¿¡æ¯\n",
    "        split_info = self._calculate_split_info(data[feature])\n",
    "\n",
    "        # é¿å…åˆ†æ¯ä¸ºé›¶\n",
    "        if split_info == 0:\n",
    "            return 0, 0\n",
    "\n",
    "        # è®¡ç®—ä¿¡æ¯å¢ç›Šæ¯”\n",
    "        info_gain_ratio = information_gain / split_info\n",
    "\n",
    "        return info_gain_ratio, None  # å¯¹äºç¦»æ•£ç‰¹å¾ï¼Œä¸éœ€è¦é˜ˆå€¼\n",
    "\n",
    "    # è®¡ç®—å¤„ç†è¿ç»­ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šæ¯”\n",
    "    def _calculate_info_gain_ratio_continuous(self, data, feature):\n",
    "        # æ’åºå¹¶è·å–å”¯ä¸€å€¼\n",
    "        unique_values = np.unique(data[feature])\n",
    "        unique_values.sort()\n",
    "\n",
    "        best_info_gain_ratio = -1\n",
    "        best_threshold = None\n",
    "\n",
    "        # éå†æ¯ä¸ªå¯èƒ½çš„é˜ˆå€¼,è®¡ç®—æ¯ä¸ªé˜ˆå€¼ä¸‹çš„ä¿¡æ¯å¢ç›Šæ¯”\n",
    "        for i in range(len(unique_values) - 1):\n",
    "            threshold = (unique_values[i] + unique_values[i + 1]) / 2\n",
    "            info_gain_ratio, _ = self._calculate_info_gain_ratio_continuous_with_threshold(data, feature, threshold)\n",
    "\n",
    "            # é€‰æ‹©æœ€å¤§çš„ä¿¡æ¯å¢ç›Šæ¯”å’Œç›¸åº”çš„é˜ˆå€¼\n",
    "            if info_gain_ratio > best_info_gain_ratio:\n",
    "                best_info_gain_ratio = info_gain_ratio\n",
    "                best_threshold = threshold\n",
    "\n",
    "        return best_info_gain_ratio, best_threshold\n",
    "    \n",
    "    # è®¡ç®—ç»™å®šé˜ˆå€¼ä¸‹çš„ä¿¡æ¯å¢ç›Šæ¯”\n",
    "    def _calculate_info_gain_ratio_continuous_with_threshold(self, data, feature, threshold):\n",
    "        # åˆ†å‰²æ•°æ®\n",
    "        left_subset = data[data[feature] <= threshold]\n",
    "        right_subset = data[data[feature] > threshold]\n",
    "\n",
    "        # è®¡ç®—åŸå§‹æ•°æ®çš„ä¿¡æ¯ç†µ\n",
    "        original_entropy = self._calculate_entropy(data.iloc[:, -1])\n",
    "\n",
    "        # è®¡ç®—æŒ‰å½“å‰ç‰¹å¾åˆ†è£‚åçš„æ¡ä»¶ç†µ\n",
    "        left_weight = len(left_subset) / len(data)\n",
    "        right_weight = len(right_subset) / len(data)\n",
    "\n",
    "        left_subset_entropy = self._calculate_entropy(left_subset.iloc[:, -1])\n",
    "        right_subset_entropy = self._calculate_entropy(right_subset.iloc[:, -1])\n",
    "\n",
    "        weighted_entropy = left_weight * left_subset_entropy + right_weight * right_subset_entropy\n",
    "\n",
    "        # è®¡ç®—ä¿¡æ¯å¢ç›Š\n",
    "        information_gain = original_entropy - weighted_entropy\n",
    "\n",
    "        # è®¡ç®—åˆ†è£‚ä¿¡æ¯\n",
    "        split_info = self._calculate_split_info_continuous(data[feature], threshold)\n",
    "\n",
    "        # é¿å…åˆ†æ¯ä¸ºé›¶\n",
    "        if split_info == 0:\n",
    "            return 0, threshold\n",
    "\n",
    "        # è®¡ç®—ä¿¡æ¯å¢ç›Šæ¯”\n",
    "        info_gain_ratio = information_gain / split_info\n",
    "\n",
    "        return info_gain_ratio, threshold\n",
    "\n",
    "    # è®¡ç®—åˆ†è£‚ä¿¡æ¯ï¼ˆç¦»æ•£ç‰¹å¾ï¼‰\n",
    "    def _calculate_split_info(self, x):\n",
    "        _, counts = np.unique(x, return_counts=True)\n",
    "        probabilities = counts / len(x)\n",
    "        return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "\n",
    "     # è®¡ç®—åˆ†è£‚ä¿¡æ¯ï¼ˆè¿ç»­ç‰¹å¾ï¼‰\n",
    "    def _calculate_split_info_continuous(self, x, threshold):\n",
    "        left_probability = np.sum(x <= threshold) / len(x)\n",
    "        right_probability = 1 - left_probability\n",
    "        return -left_probability * np.log2(left_probability + 1e-10) - right_probability * np.log2(right_probability + 1e-10)\n",
    "\n",
    "    # æ–°æ ·æœ¬çš„é¢„æµ‹é€»è¾‘\n",
    "    # éå†å†³ç­–æ ‘è¿›è¡Œé¢„æµ‹\n",
    "    def predict(self, X):       \n",
    "        predictions = []\n",
    "        for _, sample in X.iterrows():\n",
    "            predictions.append(self._traverse_tree(sample, self.tree))\n",
    "        return np.array(predictions)\n",
    "\n",
    "    # é€’å½’éå†å†³ç­–æ ‘ï¼Œç›´åˆ°å¶å­èŠ‚ç‚¹\n",
    "    def _traverse_tree(self, sample, node):\n",
    "        if 'class' in node:\n",
    "            return node['class']\n",
    "        else:\n",
    "            if sample[node['feature']] <= node['threshold']:\n",
    "                return self._traverse_tree(sample, node['left'])\n",
    "            else:\n",
    "                return self._traverse_tree(sample, node['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f7c4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c45_tree = C45DecisionTree(min_samples_split=2, max_depth=None)\n",
    "c45_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c57a5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 Classification Accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "y_pred = c45_tree.predict(X_test)\n",
    "accuracy_c4_5 = accuracy_score(y_test, y_pred)\n",
    "print(f\"C4.5 Classification Accuracy: {accuracy_c4_5:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c603fc76",
   "metadata": {},
   "source": [
    "\n",
    "### CARTç®—æ³•\n",
    "- ID3å’ŒC4.5è™½ç„¶åœ¨å¯¹è®­ç»ƒæ ·æœ¬é›†çš„å­¦ä¹ ä¸­å¯ä»¥å°½å¯èƒ½å¤šçš„æŒ–æ˜ä¿¡æ¯ï¼Œä½†å…¶ç”Ÿæˆçš„å†³ç­–æ ‘åˆ†æ”¯è¾ƒå¤§ï¼Œè§„æ¨¡è¾ƒå¤§ã€‚ä¸ºäº†ç®€åŒ–å†³ç­–æ ‘çš„è§„æ¨¡ï¼Œæé«˜ç”Ÿæˆå†³ç­–æ ‘çš„æ•ˆç‡ï¼Œå°±å‡ºç°äº†æ ¹æ®**åŸºå°¼æŒ‡æ•°**æ¥é€‰æ‹©çš„CARTï¼› \n",
    "- å¯¹äºç»™å®šçš„æ ·æœ¬é›†åˆ ï¼Œå…¶åŸºå°¼æŒ‡æ•°ä¸ºï¼š $$ {Gini}(D)=1-\\sum_{k=1}^{K}\\left(\\frac{\\left|C_{k}\\right|}{|D|}\\right)^{2} $$\n",
    "   å…¶ä¸­$ğ¶_ğ‘˜$æ˜¯ğ·ä¸­å±äºç¬¬ğ‘˜ç±»çš„æ ·æœ¬å­é›†ï¼ŒKæ˜¯ç±»çš„ä¸ªæ•°ã€‚\n",
    "- åŸºå°¼ç³»æ•°çš„æ€§è´¨ä¸ä¿¡æ¯ç†µä¸€æ ·ï¼š\n",
    "   åº¦é‡éšæœºå˜é‡çš„ä¸ç¡®å®šåº¦çš„å¤§å°ï¼›åŸºå°¼æŒ‡æ•°è¶Šâ¼©è¡¨ç¤ºæ•°æ®çš„çº¯åº¦è¶Šé«˜ï¼Œåä¹‹å…¶å€¼è¶Šå¤§ï¼Œæ ·æœ¬é›†åˆçš„ä¸ç¡®å®šæ€§ä¹Ÿå°±è¶Šå¤§ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "926c15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CARTDecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    # æ„å»ºå†³ç­–æ ‘\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "         # è‹¥è¾¾åˆ°æœ€å¤§æ·±åº¦æˆ–æ ·æœ¬æ•°é‡å°äºç­‰äºé˜ˆå€¼ï¼Œåˆ™è¿”å›å¶å­èŠ‚ç‚¹\n",
    "        if self.max_depth is not None and depth == self.max_depth or len(X) <= self.min_samples_split:\n",
    "            return self._create_leaf_node(y)\n",
    "\n",
    "         # é€‰æ‹©æœ€ä½³ç‰¹å¾å’Œé˜ˆå€¼è¿›è¡Œåˆ†è£‚\n",
    "        best_feature, best_threshold = self._choose_best_split(X, y)\n",
    "\n",
    "        # è‹¥æ— æ³•æ‰¾åˆ°åˆé€‚çš„åˆ†è£‚ç‚¹ï¼Œåˆ™è¿”å›å¶å­èŠ‚ç‚¹\n",
    "        if best_feature is None:\n",
    "            return self._create_leaf_node(y)\n",
    "\n",
    "        # æ ¹æ®é€‰æ‹©çš„ç‰¹å¾å’Œé˜ˆå€¼è¿›è¡Œåˆ†è£‚\n",
    "        left_indices = X[best_feature] <= best_threshold\n",
    "        right_indices = ~left_indices\n",
    "\n",
    "        # é€’å½’æ„å»ºå·¦å³å­æ ‘\n",
    "        left_subtree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return {'feature': best_feature, 'threshold': best_threshold,\n",
    "                'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "    # é€‰æ‹©æœ€ä½³ç‰¹å¾å’Œé˜ˆå€¼è¿›è¡Œåˆ†è£‚\n",
    "    def _choose_best_split(self, X, y):\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_mse = float('inf')\n",
    "\n",
    "         # éå†æ‰€æœ‰ç‰¹å¾\n",
    "        for feature in X.columns:\n",
    "            # è®¡ç®—æ¯ä¸ªç‰¹å¾å¯èƒ½çš„åˆ†è£‚ç‚¹åŠå…¶å‡æ–¹è¯¯å·®\n",
    "            thresholds, mse_values = self._calculate_mse_for_feature(X[feature], y)\n",
    "            \n",
    "             # æ£€æŸ¥mse_valuesæ˜¯å¦ä¸ºç©º\n",
    "            if len(mse_values) == 0:\n",
    "                continue\n",
    "                \n",
    "            min_mse_index = np.argmin(mse_values)\n",
    "            min_mse = mse_values[min_mse_index]\n",
    "\n",
    "            # æ›´æ–°æœ€ä½³åˆ†è£‚ç‚¹\n",
    "            if min_mse < best_mse:\n",
    "                best_mse = min_mse\n",
    "                best_feature = feature\n",
    "                best_threshold = thresholds[min_mse_index]\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    # è®¡ç®—ç»™å®šç‰¹å¾çš„æ¯ä¸ªå¯èƒ½åˆ†è£‚ç‚¹åŠå…¶å‡æ–¹è¯¯å·®\n",
    "    def _calculate_mse_for_feature(self, feature, y):\n",
    "        unique_values = np.unique(feature)\n",
    "        thresholds = (unique_values[:-1] + unique_values[1:]) / 2\n",
    "\n",
    "        mse_values = []\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            left_indices = feature <= threshold\n",
    "            right_indices = ~left_indices\n",
    "\n",
    "            mse = self._calculate_mse(y[left_indices]) + self._calculate_mse(y[right_indices])\n",
    "            mse_values.append(mse)\n",
    "\n",
    "        return thresholds, mse_values\n",
    "\n",
    "    # è®¡ç®—å‡æ–¹è¯¯å·®\n",
    "    def _calculate_mse(self, values):\n",
    "        if len(values) == 0:\n",
    "            return 0\n",
    "        mean_value = np.mean(values)\n",
    "        return np.mean((values - mean_value) ** 2)\n",
    "\n",
    "    # åˆ›å»ºå¶å­èŠ‚ç‚¹ï¼Œè¿”å›å‡å€¼ä½œä¸ºå¶å­èŠ‚ç‚¹çš„å€¼\n",
    "    def _create_leaf_node(self, y):\n",
    "        return {'value': np.mean(y)}\n",
    "\n",
    "     # å¯¹è¾“å…¥æ•°æ®è¿›è¡Œé¢„æµ‹\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for _, sample in X.iterrows():\n",
    "            predictions.append(self._traverse_tree(sample, self.tree))\n",
    "        return np.array(predictions)\n",
    "\n",
    "    # é€’å½’éå†å†³ç­–æ ‘ï¼Œè¿”å›å¶å­èŠ‚ç‚¹çš„å€¼\n",
    "    def _traverse_tree(self, sample, node):\n",
    "        if 'value' in node:\n",
    "            return node['value']\n",
    "        else:\n",
    "            if sample[node['feature']] <= node['threshold']:\n",
    "                return self._traverse_tree(sample, node['left'])\n",
    "            else:\n",
    "                return self._traverse_tree(sample, node['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47029615",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_tree = CARTDecisionTree(min_samples_split=2, max_depth=None)\n",
    "cart_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50b2ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Classification Accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "y_pred = cart_tree.predict(X_test)\n",
    "accuracy_cart = accuracy_score(y_test, y_pred)\n",
    "print(f\"CART Classification Accuracy: {accuracy_cart:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4ff42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08949992",
   "metadata": {},
   "source": [
    "### é«˜çº§è¦æ±‚\n",
    "ä½¿ç”¨ä»»æ„çš„å‰ªæç®—æ³•å¯¹æ„é€ çš„å†³ç­–æ ‘ï¼ˆåŸºæœ¬è¦æ±‚å’Œä¸­çº§è¦æ±‚æ„é€ çš„æ ‘ï¼‰è¿›è¡Œå‰ªæï¼Œè§‚å¯Ÿæµ‹è¯•é›†åˆçš„åˆ†ç±»ç²¾åº¦æ˜¯å¦æœ‰æå‡ï¼Œç»™å‡ºåˆ†æè¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814fabb",
   "metadata": {},
   "source": [
    "### å†³ç­–æ ‘çš„å‰ªæ\n",
    "- å†³ç­–æ ‘å¾ˆå®¹æ˜“å‡ºç°**è¿‡æ‹Ÿåˆç°è±¡**ã€‚åŸå› åœ¨äºå­¦ä¹ æ—¶å®Œå…¨è€ƒè™‘çš„æ˜¯å¦‚ä½•æâ¾¼å¯¹è®­ç»ƒæ•°æ®çš„æ­£ç¡®åˆ†ç±»ä»â½½æ„å»ºå‡ºè¿‡äºå¤æ‚çš„å†³ç­–æ ‘ã€‚\n",
    "- è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ç§°ä¸º**å‰ªæ**ï¼Œå³å¯¹å·²ç”Ÿæˆçš„æ ‘è¿›è¡Œç®€åŒ–ã€‚å…·ä½“åœ°ï¼Œå°±æ˜¯ä»å·²ç”Ÿæˆçš„æ ‘ä¸Šè£å‰ªæ‰â¼€äº›å­æ ‘æˆ–å¶èŠ‚ç‚¹ï¼Œå¹¶å°†å…¶æ ¹èŠ‚ç‚¹æˆ–çˆ¶èŠ‚ç‚¹ä½œä¸ºæ–°çš„å¶èŠ‚ç‚¹ã€‚ \n",
    "- å†³ç­–æ ‘çš„å‰ªæåŸºæœ¬ç­–ç•¥æœ‰**é¢„å‰ªæ (Pre-Pruning)** å’Œ **åå‰ªæ (Post-Pruning)**\n",
    "   - **é¢„å‰ªæ**ï¼šæ˜¯æ ¹æ®â¼€äº›åŸåˆ™**ææ—©çš„åœæ­¢æ ‘å¢é•¿**ï¼Œå¦‚æ ‘çš„æ·±åº¦è¾¾åˆ°ç”¨æˆ·æ‰€è¦çš„æ·±åº¦ã€èŠ‚ç‚¹ä¸­æ ·æœ¬ä¸ªæ•°å°‘äºç”¨æˆ·æŒ‡å®šä¸ªæ•°ã€ä¸çº¯åº¦æŒ‡æ ‡ä¸‹é™çš„å¹…åº¦å°äºç”¨æˆ·æŒ‡å®šçš„å¹…åº¦ç­‰ã€‚ \n",
    "   - **åå‰ªæ**ï¼šæ˜¯é€šè¿‡åœ¨å®Œå…¨ç”Ÿé•¿çš„æ ‘ä¸Šå‰ªå»åˆ†æå®ç°çš„ï¼Œé€šè¿‡åˆ é™¤èŠ‚ç‚¹çš„åˆ†æ”¯æ¥å‰ªå»æ ‘èŠ‚ç‚¹ã€‚æ˜¯åœ¨ç”Ÿæˆå†³ç­–æ ‘ä¹‹å**è‡ªåº•å‘ä¸Š**çš„å¯¹æ ‘ä¸­æ‰€æœ‰çš„éå¶ç»“ç‚¹è¿›â¾é€ä¸€è€ƒå¯Ÿ ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "913493b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrunedCARTDecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, alpha=0.1):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.alpha = alpha\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        features = X.columns\n",
    "        data = pd.concat([X, y], axis=1)\n",
    "        self.tree = self._build_tree(data, features)\n",
    "\n",
    "    def _build_tree(self, data, features, depth=0):\n",
    "        if len(data) <= self.min_samples_split or (self.max_depth is not None and depth == self.max_depth):\n",
    "            return self._create_leaf_node(data)\n",
    "\n",
    "        selected_feature, threshold = self._choose_best_split(data, features)\n",
    "\n",
    "        left_data = data[data[selected_feature] <= threshold]\n",
    "        right_data = data[data[selected_feature] > threshold]\n",
    "\n",
    "        validation_accuracy_before_split = self._calculate_accuracy(left_data, right_data)\n",
    "\n",
    "        left_leaf = self._create_leaf_node(left_data)\n",
    "        right_leaf = self._create_leaf_node(right_data)\n",
    "\n",
    "        validation_accuracy_after_split = self._calculate_accuracy(left_leaf, right_leaf)\n",
    "\n",
    "        if validation_accuracy_after_split - validation_accuracy_before_split < self.alpha:\n",
    "            return self._create_leaf_node(data)\n",
    "\n",
    "        left_subtree = self._build_tree(left_data, features, depth + 1)\n",
    "        right_subtree = self._build_tree(right_data, features, depth + 1)\n",
    "\n",
    "        return {'feature': selected_feature, 'threshold': threshold,\n",
    "                'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "    def _choose_best_split(self, data, features):\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_mse = float('inf')\n",
    "\n",
    "        for feature in features:\n",
    "            thresholds, mse_values = self._calculate_mse_for_feature(data[feature], data.iloc[:, -1])\n",
    "            min_mse_index = np.argmin(mse_values)\n",
    "            min_mse = mse_values[min_mse_index]\n",
    "\n",
    "            if min_mse < best_mse:\n",
    "                best_mse = min_mse\n",
    "                best_feature = feature\n",
    "                best_threshold = thresholds[min_mse_index]\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _calculate_mse_for_feature(self, feature, y):\n",
    "        thresholds = np.unique(feature)\n",
    "        thresholds.sort()\n",
    "\n",
    "        mse_values = []\n",
    "        for threshold in thresholds:\n",
    "            left_indices = feature <= threshold\n",
    "            right_indices = ~left_indices\n",
    "            mse = self._calculate_mse(y[left_indices]) + self._calculate_mse(y[right_indices])\n",
    "            mse_values.append(mse)\n",
    "\n",
    "        return thresholds, mse_values\n",
    "\n",
    "    def _calculate_mse(self, values):\n",
    "        if len(values) == 0:\n",
    "            return 0\n",
    "        mean_value = np.mean(values)\n",
    "        return np.mean((values - mean_value) ** 2)\n",
    "\n",
    "    def _create_leaf_node(self, data):\n",
    "        values, counts = np.unique(data.iloc[:, -1], return_counts=True)\n",
    "        return {'class': values[np.argmax(counts)]}\n",
    "\n",
    "    def _calculate_accuracy(self, left_data, right_data):\n",
    "        return len(left_data) / (len(left_data) + len(right_data))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for _, sample in X.iterrows():\n",
    "            predictions.append(self._traverse_tree(sample, self.tree))\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _traverse_tree(self, sample, node):\n",
    "        if 'class' in node:\n",
    "            return node['class']\n",
    "        else:\n",
    "            if sample[node['feature']] <= node['threshold']:\n",
    "                return self._traverse_tree(sample, node['left'])\n",
    "            else:\n",
    "                return self._traverse_tree(sample, node['right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc4d9a",
   "metadata": {},
   "source": [
    "è®¡ç®—åˆ†è£‚å‰å·¦å³å­æ ‘çš„å‡†ç¡®ç‡ï¼Œç„¶ååˆ›å»ºå·¦å³å­æ ‘çš„å¶å­èŠ‚ç‚¹ï¼Œå†è®¡ç®—åˆ†è£‚åçš„å‡†ç¡®ç‡ã€‚å¦‚æœåˆ†è£‚åçš„å‡†ç¡®ç‡å‡å»åˆ†è£‚å‰çš„å‡†ç¡®ç‡å°äº self.alphaï¼Œåˆ™é€‰æ‹©ä¸è¿›è¡Œåˆ†è£‚ï¼Œè€Œæ˜¯ç›´æ¥è¿”å›ä¸€ä¸ªåŒ…å«æ•´ä¸ªæ•°æ®çš„å¶å­èŠ‚ç‚¹ï¼Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "00c6eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_cart_tree = PrunedCARTDecisionTree(min_samples_split=2, max_depth=None, alpha=0.1)\n",
    "pruned_cart_tree.fit(X_train, y_train)\n",
    "\n",
    "# tree = C45DecisionTree(min_samples_split=2, max_depth=None)\n",
    "# tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8494172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned CART Classification Accuracy: 0.40\n"
     ]
    }
   ],
   "source": [
    "# é¢„æµ‹å¹¶è¾“å‡ºåˆ†ç±»ç²¾åº¦\n",
    "y_pred = pruned_cart_tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Pruned CART Classification Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05902b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68e85e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrunedC45DecisionTree:\n",
    "    \n",
    "    \"\"\"\n",
    "    min_samples_split: int, optional (default=2)\n",
    "          èŠ‚ç‚¹åˆ†è£‚çš„æœ€å°æ ·æœ¬æ•°\n",
    "    max_depth: int or None, optional (default=None)\n",
    "          æ ‘çš„æœ€å¤§æ·±åº¦ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™èŠ‚ç‚¹ä¼šä¸€ç›´åˆ†è£‚ï¼Œç›´åˆ°æ¯ä¸ªå¶å­èŠ‚ç‚¹çš„æ ·æœ¬æ•°å°äºmin_samples_split     \n",
    "    tree: dict\n",
    "          å­˜å‚¨æ„å»ºå¥½çš„å†³ç­–æ ‘çš„å­—å…¸    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, min_samples_split=2, max_depth=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    # è®¡ç®—ä¿¡æ¯ç†µ\n",
    "    def _calculate_entropy(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "    \n",
    "    # æ ¹æ®è®­ç»ƒæ•°æ®æ‹ŸåˆC4.5å†³ç­–æ ‘\n",
    "    def fit(self, X, y, n_folds=5):\n",
    "        features = X.columns\n",
    "        data = pd.concat([X, y], axis=1)\n",
    "\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "        for train_index, val_index in kf.split(data):\n",
    "            train_data, val_data = data.iloc[train_index], data.iloc[val_index]\n",
    "            \n",
    "            self.tree = self._build_tree(train_data, features, validation_data=val_data)\n",
    "            \n",
    "            # æ£€æŸ¥åœ¨å‰ªæå self.tree æ˜¯å¦ä¸º None\n",
    "            if self.tree is not None:\n",
    "                # å¦‚æœ self.tree ä¸æ˜¯ Noneï¼Œåˆ™æ£€æŸ¥å‰ªæåçš„å‡†ç¡®ç‡\n",
    "                pruned_tree = self._prune_tree(self.tree, val_data)\n",
    "                if pruned_tree is not None:\n",
    "                    self.tree = pruned_tree\n",
    "\n",
    "    # é€’å½’æ„å»ºC4.5å†³ç­–æ ‘\n",
    "    def _build_tree(self, data, features, depth=0, validation_data=None):\n",
    "        # è‹¥æ ·æœ¬æ•°é‡å°äºç­‰äºé˜ˆå€¼æˆ–æ·±åº¦è¾¾åˆ°æœ€å¤§æ·±åº¦ï¼Œåˆ™è¿”å›å¶å­èŠ‚ç‚¹\n",
    "        if len(data) <= self.min_samples_split or (self.max_depth is not None and depth == self.max_depth):\n",
    "            return self._create_leaf_node(data)\n",
    "\n",
    "        # é€‰æ‹©æœ€ä½³ç‰¹å¾å’Œé˜ˆå€¼è¿›è¡Œåˆ†è£‚\n",
    "        selected_feature, threshold = self._choose_best_feature(data, features)\n",
    "\n",
    "        # æ ¹æ®é€‰æ‹©çš„ç‰¹å¾å’Œé˜ˆå€¼è¿›è¡Œåˆ†è£‚\n",
    "        left_data = data[data[selected_feature] <= threshold]\n",
    "        right_data = data[data[selected_feature] > threshold]\n",
    "\n",
    "        # é€’å½’æ„å»ºå·¦å³å­æ ‘\n",
    "        left_subtree = self._build_tree(left_data, features, depth + 1)\n",
    "        right_subtree = self._build_tree(right_data, features, depth + 1)\n",
    "\n",
    "        # æ„å»ºå®Œæ•´çš„æ ‘\n",
    "        self.tree = {'feature': selected_feature, 'threshold': threshold, 'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "         # è¿›è¡Œåå‰ªæ\n",
    "        if validation_data is not None:\n",
    "            pruned_tree = self._prune_tree(self.tree, validation_data)\n",
    "            if pruned_tree is not None:\n",
    "                self.tree = pruned_tree\n",
    " \n",
    "        return self.tree\n",
    "   \n",
    "    def _prune_tree(self, tree, validation_data):\n",
    "        if 'left' in tree and 'right' in tree:\n",
    "            left_subtree = tree['left']\n",
    "            right_subtree = tree['right']\n",
    "\n",
    "            if 'class' not in left_subtree and 'class' not in right_subtree:\n",
    "                # å¦‚æœå·¦å³å­æ ‘éƒ½ä¸æ˜¯å¶å­èŠ‚ç‚¹ï¼Œåˆ™é€’å½’å‰ªæ\n",
    "                tree['left'] = self._prune_tree(left_subtree, validation_data)\n",
    "                tree['right'] = self._prune_tree(right_subtree, validation_data)\n",
    "\n",
    "                # å¦‚æœå‰ªæåçš„å‡†ç¡®ç‡æ›´é«˜ï¼Œåˆ™åˆå¹¶ä¸ºå¶å­èŠ‚ç‚¹\n",
    "                before_pruning_accuracy = self._calculate_accuracy(validation_data, tree)\n",
    "                tree['class'] = self._majority_class(validation_data)\n",
    "                after_pruning_accuracy = self._calculate_accuracy(validation_data, tree)\n",
    "\n",
    "                if after_pruning_accuracy >= before_pruning_accuracy:\n",
    "                    # å¦‚æœå‡†ç¡®ç‡æé«˜æˆ–ä¿æŒä¸å˜ï¼Œåˆ™è¿”å›å¶å­èŠ‚ç‚¹\n",
    "                    return {'class': tree['class']}\n",
    "\n",
    "        return tree\n",
    "    \n",
    "    def _calculate_accuracy(self, data, tree):\n",
    "        predictions = self.predict(data.iloc[:, :-1])\n",
    "        actual_labels = data.iloc[:, -1].to_numpy()\n",
    "        accuracy = np.mean(predictions == actual_labels)\n",
    "        return accuracy\n",
    "    \n",
    "    def _majority_class(self, data):\n",
    "        values, counts = np.unique(data.iloc[:, -1], return_counts=True)\n",
    "        return values[np.argmax(counts)]\n",
    "    \n",
    "    # åˆ›å»ºå¶å­èŠ‚ç‚¹ï¼ŒåŒ…å«æ•°æ®é›†ä¸­å‡ºç°æœ€é¢‘ç¹çš„ç±»åˆ«\n",
    "    def _create_leaf_node(self, data):\n",
    "        values, counts = np.unique(data.iloc[:, -1], return_counts=True)\n",
    "        return {'class': values[np.argmax(counts)]}\n",
    "    \n",
    "    # é€‰æ‹©æœ€ä½³ç‰¹å¾å’Œé˜ˆå€¼è¿›è¡Œåˆ†è£‚\n",
    "    def _choose_best_feature(self, data, features):\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_info_gain_ratio = -1\n",
    "\n",
    "        for feature in features:\n",
    "            if data[feature].dtype == 'object':\n",
    "                # å¤„ç†ç¦»æ•£ç‰¹å¾\n",
    "                info_gain_ratio, threshold = self._calculate_info_gain_ratio(data, feature)\n",
    "            else:\n",
    "                # å¤„ç†è¿ç»­ç‰¹å¾\n",
    "                info_gain_ratio, threshold = self._calculate_info_gain_ratio_continuous(data, feature)\n",
    "\n",
    "            # é€‰æ‹©ä¿¡æ¯å¢ç›Šæ¯”æœ€å¤§çš„ç‰¹å¾å’Œç›¸åº”çš„é˜ˆå€¼\n",
    "            if info_gain_ratio > best_info_gain_ratio:\n",
    "                best_info_gain_ratio = info_gain_ratio\n",
    "                best_feature = feature\n",
    "                best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    # è®¡ç®—ä¿¡æ¯å¢ç›Šæ¯”\n",
    "    def _calculate_info_gain_ratio(self, data, feature):\n",
    "\n",
    "        # è®¡ç®—åŸå§‹æ•°æ®çš„ä¿¡æ¯ç†µ\n",
    "        original_entropy = self._calculate_entropy(data.iloc[:, -1])\n",
    "\n",
    "        # è®¡ç®—æŒ‰å½“å‰ç‰¹å¾åˆ†è£‚åçš„æ¡ä»¶ç†µ\n",
    "        values, counts = np.unique(data[feature], return_counts=True)\n",
    "        weighted_entropy = 0\n",
    "        for value, count in zip(values, counts):\n",
    "            subset_indices = data[data[feature] == value].index\n",
    "            subset_entropy = self._calculate_entropy(data.loc[subset_indices].iloc[:, -1])\n",
    "            weighted_entropy += count / len(data) * subset_entropy\n",
    "\n",
    "        # è®¡ç®—ä¿¡æ¯å¢ç›Š\n",
    "        information_gain = original_entropy - weighted_entropy\n",
    "\n",
    "        # è®¡ç®—åˆ†è£‚ä¿¡æ¯\n",
    "        split_info = self._calculate_split_info(data[feature])\n",
    "\n",
    "        # é¿å…åˆ†æ¯ä¸ºé›¶\n",
    "        if split_info == 0:\n",
    "            return 0, 0\n",
    "\n",
    "        # è®¡ç®—ä¿¡æ¯å¢ç›Šæ¯”\n",
    "        info_gain_ratio = information_gain / split_info\n",
    "\n",
    "        return info_gain_ratio, None  # å¯¹äºç¦»æ•£ç‰¹å¾ï¼Œä¸éœ€è¦é˜ˆå€¼\n",
    "\n",
    "    # è®¡ç®—å¤„ç†è¿ç»­ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šæ¯”\n",
    "    def _calculate_info_gain_ratio_continuous(self, data, feature):\n",
    "        # æ’åºå¹¶è·å–å”¯ä¸€å€¼\n",
    "        unique_values = np.unique(data[feature])\n",
    "        unique_values.sort()\n",
    "\n",
    "        best_info_gain_ratio = -1\n",
    "        best_threshold = None\n",
    "\n",
    "        # éå†æ¯ä¸ªå¯èƒ½çš„é˜ˆå€¼,è®¡ç®—æ¯ä¸ªé˜ˆå€¼ä¸‹çš„ä¿¡æ¯å¢ç›Šæ¯”\n",
    "        for i in range(len(unique_values) - 1):\n",
    "            threshold = (unique_values[i] + unique_values[i + 1]) / 2\n",
    "            info_gain_ratio, _ = self._calculate_info_gain_ratio_continuous_with_threshold(data, feature, threshold)\n",
    "\n",
    "            # é€‰æ‹©æœ€å¤§çš„ä¿¡æ¯å¢ç›Šæ¯”å’Œç›¸åº”çš„é˜ˆå€¼\n",
    "            if info_gain_ratio > best_info_gain_ratio:\n",
    "                best_info_gain_ratio = info_gain_ratio\n",
    "                best_threshold = threshold\n",
    "\n",
    "        return best_info_gain_ratio, best_threshold\n",
    "    \n",
    "    # è®¡ç®—ç»™å®šé˜ˆå€¼ä¸‹çš„ä¿¡æ¯å¢ç›Šæ¯”\n",
    "    def _calculate_info_gain_ratio_continuous_with_threshold(self, data, feature, threshold):\n",
    "        # åˆ†å‰²æ•°æ®\n",
    "        left_subset = data[data[feature] <= threshold]\n",
    "        right_subset = data[data[feature] > threshold]\n",
    "\n",
    "        # è®¡ç®—åŸå§‹æ•°æ®çš„ä¿¡æ¯ç†µ\n",
    "        original_entropy = self._calculate_entropy(data.iloc[:, -1])\n",
    "\n",
    "        # è®¡ç®—æŒ‰å½“å‰ç‰¹å¾åˆ†è£‚åçš„æ¡ä»¶ç†µ\n",
    "        left_weight = len(left_subset) / len(data)\n",
    "        right_weight = len(right_subset) / len(data)\n",
    "\n",
    "        left_subset_entropy = self._calculate_entropy(left_subset.iloc[:, -1])\n",
    "        right_subset_entropy = self._calculate_entropy(right_subset.iloc[:, -1])\n",
    "\n",
    "        weighted_entropy = left_weight * left_subset_entropy + right_weight * right_subset_entropy\n",
    "\n",
    "        # è®¡ç®—ä¿¡æ¯å¢ç›Š\n",
    "        information_gain = original_entropy - weighted_entropy\n",
    "\n",
    "        # è®¡ç®—åˆ†è£‚ä¿¡æ¯\n",
    "        split_info = self._calculate_split_info_continuous(data[feature], threshold)\n",
    "\n",
    "        # é¿å…åˆ†æ¯ä¸ºé›¶\n",
    "        if split_info == 0:\n",
    "            return 0, threshold\n",
    "\n",
    "        # è®¡ç®—ä¿¡æ¯å¢ç›Šæ¯”\n",
    "        info_gain_ratio = information_gain / split_info\n",
    "\n",
    "        return info_gain_ratio, threshold\n",
    "\n",
    "    # è®¡ç®—åˆ†è£‚ä¿¡æ¯ï¼ˆç¦»æ•£ç‰¹å¾ï¼‰\n",
    "    def _calculate_split_info(self, x):\n",
    "        _, counts = np.unique(x, return_counts=True)\n",
    "        probabilities = counts / len(x)\n",
    "        return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "\n",
    "     # è®¡ç®—åˆ†è£‚ä¿¡æ¯ï¼ˆè¿ç»­ç‰¹å¾ï¼‰\n",
    "    def _calculate_split_info_continuous(self, x, threshold):\n",
    "        left_probability = np.sum(x <= threshold) / len(x)\n",
    "        right_probability = 1 - left_probability\n",
    "        return -left_probability * np.log2(left_probability + 1e-10) - right_probability * np.log2(right_probability + 1e-10)\n",
    "\n",
    "    # æ–°æ ·æœ¬çš„é¢„æµ‹é€»è¾‘\n",
    "    # éå†å†³ç­–æ ‘è¿›è¡Œé¢„æµ‹\n",
    "    def predict(self, X):       \n",
    "        predictions = []\n",
    "        for _, sample in X.iterrows():\n",
    "            predictions.append(self._traverse_tree(sample, self.tree))\n",
    "        return np.array(predictions)\n",
    "\n",
    "    # é€’å½’éå†å†³ç­–æ ‘ï¼Œç›´åˆ°å¶å­èŠ‚ç‚¹\n",
    "    def _traverse_tree(self, sample, node):\n",
    "        if 'class' in node:\n",
    "            return node['class']\n",
    "        else:\n",
    "            if sample[node['feature']] <= node['threshold']:\n",
    "                return self._traverse_tree(sample, node['left'])\n",
    "            else:\n",
    "                return self._traverse_tree(sample, node['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f0cc8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_c45_tree = PrunedC45DecisionTree(min_samples_split=2, max_depth=None)\n",
    "pruned_c45_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d05ecbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 Classification Accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "y_pred = pruned_c45_tree.predict(X_test)\n",
    "accuracy_pruned_c45 = accuracy_score(y_test, y_pred)\n",
    "print(f\"C4.5 Classification Accuracy: {accuracy_pruned_c45:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c961d",
   "metadata": {},
   "source": [
    "### å†³ç­–æ ‘çš„å‰ªæ \n",
    "- å†³ç­–æ ‘çš„å‰ªæåŸºæœ¬ç­–ç•¥æœ‰**é¢„å‰ªæ (Pre-Pruning)** å’Œ **åå‰ªæ (Post-Pruning)**\n",
    "   - **é¢„å‰ªæ**ï¼šæ˜¯æ ¹æ®â¼€äº›åŸåˆ™**ææ—©çš„åœæ­¢æ ‘å¢é•¿**ï¼Œå¦‚æ ‘çš„æ·±åº¦è¾¾åˆ°ç”¨æˆ·æ‰€è¦çš„æ·±åº¦ã€èŠ‚ç‚¹ä¸­æ ·æœ¬ä¸ªæ•°å°‘äºç”¨æˆ·æŒ‡å®šä¸ªæ•°ã€ä¸çº¯åº¦æŒ‡æ ‡ä¸‹é™çš„å¹…åº¦å°äºç”¨æˆ·æŒ‡å®šçš„å¹…åº¦ç­‰ã€‚ \n",
    "   - **åå‰ªæ**ï¼šæ˜¯é€šè¿‡åœ¨å®Œå…¨ç”Ÿé•¿çš„æ ‘ä¸Šå‰ªå»åˆ†æå®ç°çš„ï¼Œé€šè¿‡åˆ é™¤èŠ‚ç‚¹çš„åˆ†æ”¯æ¥å‰ªå»æ ‘èŠ‚ç‚¹ã€‚æ˜¯åœ¨ç”Ÿæˆå†³ç­–æ ‘ä¹‹å**è‡ªåº•å‘ä¸Š**çš„å¯¹æ ‘ä¸­æ‰€æœ‰çš„éå¶ç»“ç‚¹è¿›â¾é€ä¸€è€ƒå¯Ÿ ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be509445",
   "metadata": {},
   "source": [
    "é¢„å‰ªæ\n",
    "- é¢„å‰ªæèƒ½å¤Ÿå‡å°‘å†³ç­–æ ‘çš„è§„æ¨¡ï¼Œå› ä¸ºå®ƒåœ¨æ„å»ºæ ‘çš„è¿‡ç¨‹ä¸­å°±è¿›è¡Œäº†å‰ªæã€‚è¿™å¯ä»¥å‡å°‘æ¨¡å‹çš„å¤æ‚æ€§ï¼Œé™ä½è¿‡æ‹Ÿåˆçš„é£é™©.\n",
    "- é¢„å‰ªææœ‰åŠ©äºé˜²æ­¢å†³ç­–æ ‘åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿‡åˆ†æ‹Ÿåˆï¼Œä½†è¿‡æ—©åœæ­¢åˆ’åˆ†å¯èƒ½å¯¼è‡´æ¨¡å‹æ— æ³•å­¦ä¹ å¤æ‚çš„æ¨¡å¼ï¼Œå¢åŠ äº†æ¬ æ‹Ÿåˆçš„é£é™©\n",
    "\n",
    "åå‰ªæ\n",
    "- åå‰ªæåœ¨æ„å»ºå®Œæ•´ä¸ªæ ‘åè¿›è¡Œï¼Œç›¸æ¯”äºé¢„å‰ªæï¼Œå®ƒæ›´çµæ´»ï¼Œå¯ä»¥æ›´å¥½åœ°é€‚åº”æ•°æ®çš„å¤æ‚æ€§ã€‚åå‰ªæé€šè¿‡å‰ªæå†³ç­–æ ‘çš„ä¸€éƒ¨åˆ†ï¼Œæœ‰åŠ©äºæé«˜æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½\n",
    "- é€šè¿‡å‡å°‘æ ‘çš„å¤æ‚æ€§ï¼Œæœ‰åŠ©äºé˜²æ­¢è¿‡æ‹Ÿåˆã€‚å®ƒå¯ä»¥æ ¹æ®éªŒè¯é›†æˆ–äº¤å‰éªŒè¯çš„æ€§èƒ½æ¥ç¡®å®šå“ªäº›èŠ‚ç‚¹éœ€è¦å‰ªæ\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a3d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39964cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0072cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae33af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691933d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249c20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a1522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460be7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b05de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f3a133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f93544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d125e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb5dfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c4e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2a156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841bc841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6fcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab7547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986fb847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a841b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
